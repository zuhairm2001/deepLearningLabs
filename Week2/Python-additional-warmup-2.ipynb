{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Python-additional-warmup-2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XUOCPxEUHYYH","colab_type":"text"},"source":["# Python Additional Warmup Task Session-2\n","\n","In this session we will implementing common activation functions used in neural networks, and also plot them.\n","\n","**Note**: Before running the code for testing, please check the expected output."]},{"cell_type":"code","metadata":{"id":"R5IbQbBiG-3q","colab_type":"code","colab":{}},"source":["## Import the required packages ##\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","print(np.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LBQW5o5iICR0","colab_type":"text"},"source":["## Task 1.1: Implement the following function and plot the result\n","\n","$$tanh‚Å°(ùë•)=\\frac{2}{1+ e^{-2ùë• }}  ‚àí1$$\n","\n","\n","Hint: use np.exp() for $e^{x}$"]},{"cell_type":"code","metadata":{"id":"0-YsjdurUiBT","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ## (~ 1 line)\n","def tanh(x):\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFjwr8pqZ6hi","colab_type":"code","colab":{}},"source":["## Test the function and Plot the result ##\n","x = np.linspace(-np.pi, np.pi, 12)\n","print(\"Input Values:\", x)\n","out = tanh(x)\n","print(\"Output Values:\", out)\n","\n","# Plot the result # \n","plt.plot(x, out, color = 'red', marker = \"o\") \n","plt.title(\"tanh()\") \n","plt.xlabel(\"X\") \n","plt.ylabel(\"Y\") \n","plt.show() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0i9z1_oMbxNv","colab_type":"text"},"source":["## Task 1.2: Implement the tanh(x) function using the numpy.tanh() and plot the result"]},{"cell_type":"code","metadata":{"id":"ZdS33NC5b-WA","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ## (~ 1 line)\n","# Create the input values\n","x = np.linspace(-np.pi, np.pi, 12)\n","print(\"Input Values:\", x)\n","\n","out =  # Hint: call the np.tanh() function here and pass the input values\n","print(\"Output Values:\", out)\n","\n","# Plot the result #\n","plt.plot(x, out, color = 'red', marker = \"o\") \n","plt.title(\"numpy.tanh()\") \n","plt.xlabel(\"X\") \n","plt.ylabel(\"Y\") \n","plt.show() \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ryG2f5HhCZ8","colab_type":"text"},"source":["## Task 1.3: Implement sigmoid function as given below and plot the result \n","$\\sigma(z) = \\frac{1}{1 + e^{-(z)}}$\n"]},{"cell_type":"code","metadata":{"id":"YJG9gP4shKJx","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ## (~ 4 line)\n","def sigmoid(x):\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vFSjq4dnPo0","colab_type":"code","colab":{}},"source":["## Test the function and Plot the result ##\n","x = np.linspace(-np.pi, np.pi, 12)\n","print(\"Input Values:\", x)\n","out = sigmoid(x)\n","print(\"Output Values:\", out)\n","\n","# Plot the result #\n","plt.plot(x, out, color = 'red', marker = \"o\") \n","plt.title(\"sigmoid()\") \n","plt.xlabel(\"X\") \n","plt.ylabel(\"Y\") \n","#out = tanh(x)\n","#plt.plot(x, out, color = 'blue', marker = \"x\")\n","plt.show() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ux99p3xmU5-8","colab_type":"text"},"source":["## Task 2: Implement the following function and plot the result\n","\n","$$ReLu(x) = max(0,x) $$\n","\n"]},{"cell_type":"code","metadata":{"id":"N-rZRGk4pJvc","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ## (~ 1 line)\n","def ReLU(x):\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZaBoOLbAdio4","colab_type":"code","colab":{}},"source":["## Test the function and Plot the result ##\n","# Write your code here ## (~ 7 lines)\n","X = np.linspace(-5, 5, 100)\n","plt.plot(X, ReLU(X),'b')\n","plt.xlabel('X Axis')\n","plt.ylabel('Y Axis')\n","plt.title('ReLU Function')\n","plt.text(3, 0.8, r'$ReLU(x)=max(0.0, x)$', fontsize=16)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9A_ODlDMVa0J","colab_type":"text"},"source":["## Task 3: Implement the following function and Plot the result \n","\n","$$LeakyReLu(x)=max(ax , x)$$"]},{"cell_type":"code","metadata":{"id":"KpsuRN6cVLL8","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE ## (~ 1 line)\n","def leakyReLu(x, a):\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKpDBUAwd0jt","colab_type":"code","colab":{}},"source":["## Test the function and Plot the result ##\n","X = np.linspace(-10, 10, 100)\n","plt.plot(X, leakyReLu(X, 0.1),'b')\n","plt.xlabel('X Axis')\n","plt.ylabel('Y Axis')\n","plt.title('Leaky ReLU Function')\n","plt.text(3, 0.8, r'$LeakyReLU(x)=max(ax, x)$', fontsize=16)\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KjEII_GEVvg4","colab_type":"text"},"source":["## Task 4: Implement the following function\n","\n","$$softmax(x_i) = \\frac{e^{x_i}}{\\sum_j (e^{x_j})},    j = 1, 2, ..., k.$$ "]},{"cell_type":"code","metadata":{"id":"-hphojGSVy9F","colab_type":"code","colab":{}},"source":["### WRITE YOUR CODE HERE ## (~ 1 to 3 line based on how it is implememted)\n","def softmax(x):\n","    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJBTISEfYQ4h","colab_type":"code","colab":{}},"source":["## Test your code ##\n","x = [2, 1, 0.1]\n","softmax(x)\n","\n","## Expected output: array([0.65900114, 0.24243297, 0.09856589])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7CVj5FV4r_S7","colab_type":"text"},"source":["## Task 5: Create a class named \"activation\" and add the above functions to it.\n","\n","It should have the following structure\n","\n","A. Class name = \"activationFunction\"\n","\n","B. Methods:\n","1. __init__()\n","2. display(): to display the input and output values\n","3. funcPlot(): to plot the output result from respective activation functions\n","4. tanh() :  code for tanh() function\n","5. sigmoid() :  code for sigmoid() function\n","6. ReLu() : code for ReLu function\n","7. leakyReLu(): code for Leaky Relu function\n","\n","Hint: Check the [link](https://python.swaroopch.com/oop.html) for Object Oriented Programming with Python basics."]},{"cell_type":"code","metadata":{"id":"zYHKWz7NsL_H","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE AS INSTRUCTED ##\n","\n","class activationFunction: \n","  # Initialize the init method\n","  def __init__(self, x):\n","    self.x = x # variable to store input values\n","    self.out=[] # variable to store output values\n","    self.funcName=\"\" # variable to store the function which which produced the output values\n","  \n","  # Define the Display method, to display the value of input and out values\n","  def display(self):\n","    ## WRITE YOUR CODE HERE ## (~ 2 lines)\n","    print()\n","    print()\n","    \n","  # Method to Plot the input and ouput with respect to each activations functions\n","  def funcPlot(self):\n","    ## WRITE YOUR CODE HERE ## (~ 5 lines) \n","    ## Hint: Pass the self.funcName as a parameter to plt.title()\n","    ## Hint: Pass self.x and self.out to plt.plot()\n","    \n","    \n","  # Code for tanh() function\n","  def tanh(self):\n","    self.funcName = \"tanh\"\n","    self.out = ((2/(1+np.exp(-2*x)))-1)\n","  \n","  # Code for sigmoid function\n","  def sigmoid(self):\n","    ## WRITE YOUR CODE HERE ## (~ 4 lines)\n","    \n","      \n","  # Code for ReLu function\n","  def ReLU(self):\n","    ## WRITE YOUR CODE HERE ## (~ 2 lines)\n","    \n","    \n","  # Code for LeakyRelu function\n","  def leakyReLu(self, a):\n","    ## WRITE YOUR CODE HERE ## (~ 2 lines)\n","    \n","\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k93Bjt53sf0N","colab_type":"code","colab":{}},"source":["## Test your code and plot the functions ##\n","## Create Input data ##\n","x = np.linspace(-np.pi, np.pi, 12)\n","## Create an object of the activationFunction class\n","activation = activationFunction(x)\n","\n","# Call the tanh() and display the result and graph\n","activation.tanh()\n","activation.display()\n","activation.funcPlot()\n","\n","# Call the sigmoid() and display the graph\n","activation.sigmoid()\n","activation.funcPlot()\n","\n","# Call the ReLu() and display the graph\n","activation.ReLU()\n","activation.funcPlot()\n","\n","# Call the leakyReLy() and display the graph\n","activation.leakyReLu(0.2)\n","activation.funcPlot()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GcJfZBf_Wrp2","colab_type":"text"},"source":[""]}]}